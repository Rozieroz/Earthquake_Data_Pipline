{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c67bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# # Only for Python 3.12+\n",
    "# if sys.version_info >= (3, 12):\n",
    "#     try:\n",
    "#         from setuptools._distutils.version import LooseVersion\n",
    "#         import types\n",
    "#         sys.modules['distutils.version'] = types.ModuleType('distutils.version')\n",
    "#         sys.modules['distutils.version'].LooseVersion = LooseVersion\n",
    "#     except ImportError:\n",
    "#         print(\"You need to install setuptools first. Run: pip install setuptools\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04158f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta, UTC\n",
    "from sqlalchemy import create_engine, text\n",
    "import _mysql_connector\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import * #imports all datatypes... to use for schema creation\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e0b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Earthquake Data Processing\") \\\n",
    "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.32\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "user = os.getenv(\"MYSQL_USER\")\n",
    "password = os.getenv(\"MYSQL_PASSWORD\")\n",
    "host = os.getenv(\"MYSQL_HOST\")  # Default to localhost if not set\n",
    "port = os.getenv(\"MYSQL_PORT\")  # Default to 3306 if not set\n",
    "database = os.getenv(\"MYSQL_DB\")  # Default to 'earthquake_db' if not set\n",
    "\n",
    "JDBC_URL = f\"jdbc:mysql://{host}:{port}/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f2eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table.. mysql requires primary key\n",
    "def create_db_and_table():\n",
    "\n",
    "    # create database safely\n",
    "    MYSQL_URI_NO_DB = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/\"\n",
    "    engine = create_engine(MYSQL_URI_NO_DB)\n",
    "    engine_no_db = create_engine(MYSQL_URI_NO_DB, pool_pre_ping=True)\n",
    "\n",
    "    with engine_no_db.connect() as conn:\n",
    "        print(f\"Creating database if not exists: {database}\")\n",
    "        conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{database}`;\"))\n",
    "\n",
    "    # reset engine state\n",
    "    engine_no_db.dispose()\n",
    "\n",
    "\n",
    "    # connect to db and create table\n",
    "    MYSQL_URI = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    engine = create_engine(MYSQL_URI, pool_pre_ping=True)\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS earthquake_events (\n",
    "                id VARCHAR(100) PRIMARY KEY,\n",
    "                place TEXT,\n",
    "                magnitude DOUBLE,\n",
    "                time DATETIME,\n",
    "                longitude DOUBLE,\n",
    "                latitude DOUBLE,\n",
    "                depth DOUBLE\n",
    "            );\n",
    "        \"\"\"))\n",
    "\n",
    "        engine.dispose()\n",
    "        print(\"Table 'earthquake_events' updated in MySQL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e39eb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script fetches earthquake data from the USGS Earthquake API for the past 1 hr\n",
    "\n",
    "def fetch_earthquake_data():\n",
    "    endtime = datetime.now(UTC)\n",
    "    starttime = endtime - timedelta(minutes=60)\n",
    "\n",
    "    # Format timestamps in ISO8601 as required by API\n",
    "    start_str = starttime.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    end_str = endtime.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "    url = (\n",
    "        \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "        f\"?format=geojson&starttime={start_str}&endtime={end_str}\"\n",
    "    )\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad responses\n",
    "    data = response.json()\n",
    "\n",
    "    features = data.get(\"features\", [])\n",
    "    earthquakes = []\n",
    "\n",
    "    for f in features:\n",
    "        props = f[\"properties\"]\n",
    "        coords = f[\"geometry\"][\"coordinates\"]\n",
    "        earthquakes.append({\n",
    "            \"id\": f[\"id\"],\n",
    "            \"place\": props[\"place\"],\n",
    "            \"magnitude\": float(props[\"mag\"]) if props[\"mag\"] is not None else None,\n",
    "            \"time\": datetime.fromtimestamp(props[\"time\"] / 1000.0),\n",
    "            \"longitude\": float(coords[0]),\n",
    "            \"latitude\": float(coords[1]),\n",
    "            \"depth\": float(coords[2])\n",
    "        })\n",
    "\n",
    "    return earthquakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8793be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to Spark DataFrame\n",
    "def earthquakes_to_df(data):\n",
    "    schema = StructType([\n",
    "        StructField(\"id\", StringType(), False),     #false = not nullable\n",
    "        StructField(\"place\", StringType(), True),\n",
    "        StructField(\"magnitude\", DoubleType(), True),\n",
    "        StructField(\"time\", TimestampType(), True),\n",
    "        StructField(\"longitude\", DoubleType(), True),\n",
    "        StructField(\"latitude\", DoubleType(), True),\n",
    "        StructField(\"depth\", DoubleType(), True)\n",
    "    ])\n",
    "    return spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9878ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to mysql with spark\n",
    "def load_to_mysql(df):\n",
    "    if df.count() == 0:\n",
    "        print(\"No recent earthquakes\")\n",
    "        return\n",
    "    \n",
    "    # write to MySQL\n",
    "    df.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\", f\"jdbc:mysql://{host}:{port}/{database}\") \\\n",
    "        .option(\"dbtable\", \"earthquake_events\") \\\n",
    "        .option(\"user\", user) \\\n",
    "        .option(\"password\", password) \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .save()\n",
    "    print(\"Earthquake data loaded into MySQL.\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09eac8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6bcd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+--------------------+---------+--------+------+\n",
      "|          id|               place|magnitude|                time|longitude|latitude| depth|\n",
      "+------------+--------------------+---------+--------------------+---------+--------+------+\n",
      "|tx2025sgsxkm|34 km SSW of Los ...|      1.3|2025-09-16 17:51:...| -102.081|   32.44|6.9435|\n",
      "|tx2025sgsjvw|55 km S of Whites...|      1.7|2025-09-16 17:36:...| -104.485|  31.681|6.0999|\n",
      "|tx2025sgsira|40 km E of McKinn...|      1.2|2025-09-16 17:34:...| -102.111|  32.369|4.7221|\n",
      "|ak025bwkl6p2|90 km N of Karluk...|      1.1|2025-09-16 17:10:...|-154.6913|  58.371|   0.0|\n",
      "+------------+--------------------+---------+--------------------+---------+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "earthquakes = fetch_earthquake_data()\n",
    "df = earthquakes_to_df(earthquakes)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897425c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    alternative without schema... not recommended, but useful for quick testing:\\n\\n    earthquakes = fetch_earthquake_data()\\n    df2 = spark.createDataFrame(earthquakes)  # No schema passed, datatypes are inferred automatically\\n    df2.show(truncate=False)\\n    df2.printSchema()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    alternative without schema... not recommended, but useful for quick testing:\n",
    "\n",
    "    earthquakes = fetch_earthquake_data()\n",
    "    df2 = spark.createDataFrame(earthquakes)  # No schema passed, datatypes are inferred automatically\n",
    "    df2.show(truncate=False)\n",
    "    df2.printSchema()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb038fcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# MYSQL_URI = f\"mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# # Load into MySQL using Pandas\n",
    "# def load_to_mysql(df):\n",
    "#     if df.count() == 0:\n",
    "#         print(\"No new earthquake data.\")\n",
    "#         return\n",
    "    \n",
    "#     from pyspark.sql.functions import col\n",
    "\n",
    "#     # Cast all timestamp columns to string before converting to Pandas to avoid type errors\n",
    "#     df = df.select([\n",
    "#         col(c).cast(\"string\") if dtype == \"timestamp\" else col(c)\n",
    "#         for c, dtype in df.dtypes\n",
    "#     ])\n",
    "#     # Convert Spark DataFrame to Pandas DataFrame for SQLAlchemy\n",
    "#     pdf = df.toPandas()\n",
    "#     engine = create_engine(MYSQL_URI)\n",
    "#     pdf.to_sql('earthquake_events', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc95b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating database if not exists: earthquakes\n",
      "Table 'earthquake_events' updated in MySQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+--------------------+-----------------+----------------+----------------+\n",
      "|          id|               place|magnitude|                time|        longitude|        latitude|           depth|\n",
      "+------------+--------------------+---------+--------------------+-----------------+----------------+----------------+\n",
      "|  nn00900561|50 km E of Tonopa...|      2.1|2025-07-14 09:37:...|        -116.6702|         37.9838|            15.9|\n",
      "|  nc75209667|4 km NW of Pinnac...|     1.26|2025-07-14 09:36:...|-121.176002502441|36.5511665344238|2.17000007629395|\n",
      "|  us7000qcjp|228 km E of Ustâ€™-...|      5.0|2025-07-14 09:28:...|         166.1011|         55.9153|            10.0|\n",
      "|ak0258ylj2lf|61 km WNW of Nanw...|      1.7|2025-07-14 09:27:...|        -152.9585|         59.5043|            94.8|\n",
      "|  nc75209662|8 km NNW of The G...|     0.65|2025-07-14 09:20:...|-122.817001342773|38.8296661376953|2.67000007629395|\n",
      "+------------+--------------------+---------+--------------------+-----------------+----------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquake data loaded into MySQL.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    create_db_and_table()\n",
    "\n",
    "    data = fetch_earthquake_data()\n",
    "\n",
    "    if not data:\n",
    "        print(\"No recent earthquakes.\")\n",
    "        exit()\n",
    "    else: \n",
    "        df = earthquakes_to_df(data)\n",
    "        df.show()\n",
    "\n",
    "        load_to_mysql(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
